{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e338f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21a9eb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "RECEIVALS_PATH = \"data/kernel/receivals.csv\"\n",
    "PO_PATH = \"data/kernel/purchase_orders.csv\"\n",
    "MAT_PATH = \"data/extended/materials.csv\"\n",
    "\n",
    "FORECAST_START = pd.to_datetime(\"2025-01-01\", utc=True)\n",
    "FORECAST_END = pd.to_datetime(\"2025-05-31\", utc=True)\n",
    "\n",
    "LAST_RECEIVAL_DATE = pd.Timestamp(\"2024-12-19\", tz=\"UTC\")\n",
    "\n",
    "def prepareData(receivals_path=RECEIVALS_PATH, po_path=PO_PATH, mat_path=MAT_PATH):\n",
    "    \n",
    "    # === Clean receivals ===\n",
    "    receivals = pd.read_csv(receivals_path)\n",
    "    receivals = receivals.dropna(subset=[\"rm_id\", \"purchase_order_id\", \"product_id\"])\n",
    "    receivals[\"rm_id\"] = receivals[\"rm_id\"].astype(int)\n",
    "    receivals[\"purchase_order_id\"] = receivals[\"purchase_order_id\"].astype(int)\n",
    "    receivals[\"product_id\"] = receivals[\"product_id\"].astype(int)\n",
    "    receivals[\"date_arrival\"] = pd.to_datetime(receivals[\"date_arrival\"], utc=True)\n",
    "\n",
    "    # == Clean purchase orders ==\n",
    "    purchase_orders = pd.read_csv(po_path)\n",
    "    purchase_orders = purchase_orders[purchase_orders[\"quantity\"] > 0] # Remove negative and 0 quantity orders\n",
    "    purchase_orders[\"delivery_date\"] = pd.to_datetime(purchase_orders[\"delivery_date\"], utc=True)\n",
    "\n",
    "    # == Clean materials ==\n",
    "    materials = pd.read_csv(mat_path)\n",
    "    materials = materials.dropna(subset=[\"product_id\", \"rm_id\"])\n",
    "    materials[\"product_id\"] = materials[\"product_id\"].astype(int)\n",
    "    materials[\"rm_id\"] = materials[\"rm_id\"].astype(int)\n",
    "\n",
    "    # Find rm_ids scheduled for 2025\n",
    "    po_2025 = purchase_orders[purchase_orders[\"delivery_date\"] >= FORECAST_START].copy()\n",
    "    po_2025 = po_2025.sort_values(by=\"delivery_date\")\n",
    "    materials_unique = materials.drop_duplicates(subset=[\"rm_id\", \"product_id\"])\n",
    "\n",
    "    merged_po2025_mat = po_2025.merge(materials_unique, on=[\"product_id\"], how=\"left\")\n",
    "\n",
    "    one_year_before = pd.to_datetime(\"2024-01-01\", utc=True) # Only rm_ids that had a delivery in 2024, if not they are likely out of production\n",
    "    active_rm_ids = receivals.loc[receivals[\"date_arrival\"] >= one_year_before, \"rm_id\"].unique()\n",
    "\n",
    "    merged_active = merged_po2025_mat[merged_po2025_mat[\"rm_id\"].isin(active_rm_ids)].copy()\n",
    "    scheduled_active_rm_ids = merged_active[\"rm_id\"].unique() # 38 found to be active with this method\n",
    "\n",
    "    # Find scheduled quantity for all active rm_ids/product_ids in 2025.\n",
    "    qty_rm_id_2025 = merged_active[[\"rm_id\", \"product_id\", \"delivery_date\", \"quantity\"]]\n",
    "    qty_rm_id_2025[\"delivery_date\"] = qty_rm_id_2025[\"delivery_date\"].dt.date\n",
    "\n",
    "    # Get daily total receivals per rm_id and mean/std(delay) for each rm_id\n",
    "    merged = pd.merge(purchase_orders, receivals, on=[\"purchase_order_id\", \"purchase_order_item_no\"], suffixes=(\"_receival\", \"_order\"))\n",
    "    merged = merged.sort_values(by=\"date_arrival\")\n",
    "\n",
    "    merged[\"delay\"] = (merged[\"date_arrival\"] - merged[\"delivery_date\"]).dt.days\n",
    "    merged[\"date_arrival\"] = merged[\"date_arrival\"].dt.date\n",
    "    merged[\"delivery_date\"] = merged[\"delivery_date\"].dt.date\n",
    "\n",
    "    daily_receivals = merged.groupby([\"rm_id\", \"date_arrival\"], as_index=False)[\"net_weight\"].sum()\n",
    "    daily_receivals[\"date_arrival\"] = pd.to_datetime(daily_receivals[\"date_arrival\"], utc=True)\n",
    "\n",
    "    delays = merged[[\"rm_id\", \"date_arrival\", \"delay\"]]\n",
    "\n",
    "    delay_stats = merged.groupby(\"rm_id\")[\"delay\"].agg([\"mean\", \"std\"]).reset_index()\n",
    "\n",
    "    purchase_orders[\"delivery_date\"] = purchase_orders[\"delivery_date\"].dt.date\n",
    "    receivals[\"date_arrival\"] = receivals[\"date_arrival\"].dt.date\n",
    "    daily_receivals[\"date_arrival\"] = daily_receivals[\"date_arrival\"].dt.date \n",
    "\n",
    "    return receivals, purchase_orders, daily_receivals, qty_rm_id_2025, scheduled_active_rm_ids, delays, delay_stats, active_rm_ids\n",
    "\n",
    "def getExpectedQty(rm_id, purchase_orders, mapping, forecast_start, forecast_end):\n",
    "    prod_id = getProdId(rm_id, mapping)\n",
    "    if prod_id is None:\n",
    "        return 0.0\n",
    "    expected_qty_product_id = purchase_orders.loc[\n",
    "        (purchase_orders[\"product_id\"] == prod_id) &\n",
    "        (purchase_orders[\"delivery_date\"] >= forecast_start) &\n",
    "        (purchase_orders[\"delivery_date\"] <= forecast_end),\n",
    "        \"quantity\"\n",
    "    ].sum()\n",
    "\n",
    "    return expected_qty_product_id\n",
    "\n",
    "def getProdId(rm_id, mapping):\n",
    "    row = mapping.loc[mapping[\"rm_id\"] == rm_id]\n",
    "    if row.empty:\n",
    "        return None\n",
    "    return row[\"product_id\"].iloc[0]\n",
    "\n",
    "def prob_rm_id(rm_id, mapping, receivals, forecast_start, days):\n",
    "    # Find prob of\n",
    "    prod_id = getProdId(rm_id, mapping)\n",
    "    check_from = (forecast_start - pd.Timedelta(days=days))\n",
    "    recent_prodId = receivals.loc[\n",
    "        (receivals[\"product_id\"] == prod_id) & # can be a problem with float vs int here. Maybe drop NaNs in receivals and initfy\n",
    "        (receivals[\"date_arrival\"] >= check_from) &\n",
    "        (receivals[\"date_arrival\"] < forecast_start)\n",
    "    ]\n",
    "    \n",
    "    if recent_prodId.empty:\n",
    "        return 1.0\n",
    "     \n",
    "    total_count = len(recent_prodId)\n",
    "    rm_count = (recent_prodId[\"rm_id\"] == rm_id).sum()\n",
    "    return rm_count/total_count\n",
    "\n",
    "def get_exp_qty_rm_id(rm_id, mapping, receivals, purchase_orders, forecast_start, forecast_end, histDays):\n",
    "    totExpectedQty = getExpectedQty(rm_id, purchase_orders, mapping, forecast_start, forecast_end)\n",
    "    probRmID = prob_rm_id(rm_id, mapping, receivals, forecast_start, histDays)\n",
    "    expectQty = totExpectedQty*probRmID\n",
    "    bufferQty = totExpectedQty-expectQty\n",
    "    return expectQty, bufferQty\n",
    "\n",
    "def build_features(rm_id, forecast_start, forecast_end, daily_receivals, purchase_orders, delays, mapping, receivals):\n",
    "    hist_delays = delays[delays[\"date_arrival\"] < forecast_start]\n",
    "    hist_daily_receivals = daily_receivals[daily_receivals[\"date_arrival\"] < forecast_start]\n",
    "    \n",
    "    recent_from_150 = (forecast_start - pd.Timedelta(days=150))\n",
    "    recent_from_60 = (forecast_start - pd.Timedelta(days=60))\n",
    "    recent_from_30 = (forecast_start - pd.Timedelta(days=30))\n",
    "    \n",
    "    recent_150 = daily_receivals[(daily_receivals[\"date_arrival\"] >= recent_from_150) \n",
    "                           & (daily_receivals[\"date_arrival\"] < forecast_start)].copy()\n",
    "    \n",
    "    recent_60 = daily_receivals[(daily_receivals[\"date_arrival\"] >= recent_from_60) \n",
    "                           & (daily_receivals[\"date_arrival\"] < forecast_start)].copy()\n",
    "    \n",
    "    recent_30 = daily_receivals[(daily_receivals[\"date_arrival\"] >= recent_from_30) \n",
    "                           & (daily_receivals[\"date_arrival\"] < forecast_start)].copy()\n",
    "    \n",
    "\n",
    "    full_date_range_150 = pd.date_range(\n",
    "        start=recent_from_150, \n",
    "        end=(forecast_start - pd.Timedelta(days=1)), \n",
    "        freq=\"D\"\n",
    "    )\n",
    "\n",
    "    full_date_range_60 = pd.date_range(\n",
    "        start=recent_from_60, \n",
    "        end=(forecast_start - pd.Timedelta(days=1)), \n",
    "        freq=\"D\"\n",
    "    )\n",
    "\n",
    "    full_date_range_30 = pd.date_range(\n",
    "        start=recent_from_30, \n",
    "        end=(forecast_start - pd.Timedelta(days=1)), \n",
    "        freq=\"D\"\n",
    "    )\n",
    "\n",
    "    recent_150_full = (\n",
    "        recent_150\n",
    "        .set_index(\"date_arrival\")\n",
    "        .reindex(full_date_range_150, fill_value=0)\n",
    "        .rename_axis(\"date_arrival\")\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    recent_60_full = (\n",
    "        recent_60\n",
    "        .set_index(\"date_arrival\")\n",
    "        .reindex(full_date_range_60, fill_value=0)\n",
    "        .rename_axis(\"date_arrival\")\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    recent_30_full = (\n",
    "        recent_30\n",
    "        .set_index(\"date_arrival\")\n",
    "        .reindex(full_date_range_30, fill_value=0)\n",
    "        .rename_axis(\"date_arrival\")\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    recent_150_full[\"rm_id\"] = rm_id\n",
    "    recent_60_full[\"rm_id\"] = rm_id\n",
    "    recent_30_full[\"rm_id\"] = rm_id\n",
    "\n",
    "    total_expected_quantity = purchase_orders.loc[\n",
    "        (purchase_orders[\"delivery_date\"] >= forecast_start) &\n",
    "        (purchase_orders[\"delivery_date\"] <= forecast_end),\n",
    "        \"quantity\"\n",
    "    ].sum()\n",
    "\n",
    "    mean_daily_weight_150 = recent_150_full[\"net_weight\"].mean()\n",
    "    mean_daily_weight_60 = recent_60_full[\"net_weight\"].mean()\n",
    "    mean_daily_weight_30 = recent_30_full[\"net_weight\"].mean()\n",
    "    window_length = (forecast_end-forecast_start).days + 1\n",
    "\n",
    "    expectQty_rm, bufferQty_rm = get_exp_qty_rm_id(rm_id, mapping, receivals, purchase_orders, forecast_start, forecast_end, 150)\n",
    "\n",
    "    last_delivery = hist_daily_receivals[\"date_arrival\"].max()\n",
    "    if pd.isna(last_delivery):\n",
    "        days_since_last_delivery = np.nan\n",
    "    else:\n",
    "        days_since_last_delivery = (forecast_start - last_delivery).days\n",
    "\n",
    "    features = {\n",
    "        \"rm_id\": rm_id,\n",
    "        \"forecast_start\": forecast_start,\n",
    "        \"forecast_end\": forecast_end,\n",
    "        \"window_length\": window_length,\n",
    "        \"mean_daily_weight_150\": mean_daily_weight_150,\n",
    "        \"mean_daily_weight_60\": mean_daily_weight_60,\n",
    "        \"mean_daily_weight_30\": mean_daily_weight_30,\n",
    "        \"days_since_last_delivery\": days_since_last_delivery,\n",
    "        \"num_deliveries_last_150\": len(recent_150),\n",
    "        \"avg_delivery_time\": hist_delays[\"delay\"].mean(),\n",
    "        \"std_delivery_time\": hist_delays[\"delay\"].std(),\n",
    "        \"total_expected_qty\": total_expected_quantity,\n",
    "        \"expected_qty_rm_id\": expectQty_rm,\n",
    "        \"buffer_qty\": bufferQty_rm\n",
    "\n",
    "    }\n",
    "\n",
    "    # Can make month and day etc on forecast_end\n",
    "\n",
    "    return features\n",
    "\n",
    "def buildTrainSet(receivals, daily_receivals, purchase_orders, delays, active_rm_ids, mapping, output_path):\n",
    "    train_rows = []\n",
    "    window_lengths = range(1, 151) \n",
    "    start_dates = pd.date_range(pd.to_datetime(\"2018-01-01\", utc=True), FORECAST_START, freq=\"14D\")  # slide every 14 days\n",
    "    \n",
    "    receivals_by_rm = {rid: df for rid, df in receivals.groupby(\"rm_id\")}\n",
    "    daily_by_rm = {rid: df for rid, df in daily_receivals.groupby(\"rm_id\")}\n",
    "    delays_by_rm = {rid: df for rid, df in delays.groupby(\"rm_id\")}\n",
    "    \n",
    "    for rm_id in tqdm(active_rm_ids):\n",
    "        print(\"Processing rm_id: \", rm_id)\n",
    "\n",
    "        for wl in tqdm(window_lengths):\n",
    "            for start in start_dates:\n",
    "                end = start + pd.Timedelta(days=wl - 1)\n",
    "                if end >= LAST_RECEIVAL_DATE: # last date in receivals\n",
    "                    break\n",
    "                feats = build_features(rm_id, start.date(), end.date(), \n",
    "                                       daily_by_rm.get(rm_id, pd.DataFrame()), \n",
    "                                       purchase_orders, \n",
    "                                       delays_by_rm.get(rm_id, pd.DataFrame()), \n",
    "                                       mapping, receivals_by_rm.get(rm_id, pd.DataFrame()))\n",
    "\n",
    "                cum_weight = daily_receivals.loc[\n",
    "                    (daily_receivals[\"rm_id\"] == rm_id) &\n",
    "                    (daily_receivals[\"date_arrival\"] >= start.date()) &\n",
    "                    (daily_receivals[\"date_arrival\"] <= end.date()),\n",
    "                    \"net_weight\"\n",
    "                ].sum()\n",
    "\n",
    "                feats[\"cum_weight\"] = cum_weight\n",
    "                train_rows.append(feats)\n",
    "\n",
    "    df_train = pd.DataFrame(train_rows)\n",
    "\n",
    "    df_train.to_csv(output_path, index=False)\n",
    "    \n",
    "    return df_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee367f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomSearchCV_lgbm(df_train):\n",
    "    X = df_train.drop(columns=[\"cum_weight\", \"forecast_start\", \"forecast_end\"])\n",
    "    y = df_train[\"cum_weight\"]\n",
    "\n",
    "    param_dist = {\n",
    "        \"n_estimators\": [200, 400, 600, 800, 1000],\n",
    "        \"learning_rate\": [0.005, 0.01, 0.05, 0.1],\n",
    "        \"max_depth\": [3, 5, 7, 9],  \n",
    "        \"num_leaves\": [15, 31, 63, 127],\n",
    "        \"subsample\": [0.4, 0.6, 0.8, 1.0],         \n",
    "        \"colsample_bytree\": [0.4, 0.6, 0.8, 1.0],  \n",
    "        \"min_child_samples\": [10, 20, 30, 50],\n",
    "        \"reg_alpha\": [0.0, 0.1, 0.5, 1.0],\n",
    "        \"reg_lambda\": [0.0, 0.1, 0.5, 1.0],\n",
    "        \"min_split_gain\": [0.0, 0.1, 0.2, 0.5]\n",
    "    }\n",
    "\n",
    "    model = lgb.LGBMRegressor(\n",
    "        objective=\"regression\",\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbosity=-1,\n",
    "    )\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=model,\n",
    "        param_distributions=param_dist,\n",
    "        scoring=\"neg_root_mean_squared_error\",\n",
    "        cv=tscv,\n",
    "        n_iter=5,\n",
    "        verbose=0,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    random_search.fit(X, y)\n",
    "\n",
    "    print(\"Best parameters:\", random_search.best_params_)\n",
    "    print(\"Best RMSE:\", -random_search.best_score_)\n",
    "\n",
    "    return random_search.best_estimator_, random_search.cv_results_\n",
    "\n",
    "\n",
    "def train_all_rm_ids(df_train, model_dir):\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    rm_ids = df_train[\"rm_id\"].unique()\n",
    "    results = []\n",
    "\n",
    "    for rid in tqdm(rm_ids):\n",
    "        print(f\"\\nTraining rm_id {rid}\")\n",
    "        df_rm = df_train[df_train[\"rm_id\"] == rid].copy()\n",
    "\n",
    "        df_rm = df_rm.reset_index(drop=True)\n",
    "\n",
    "        model, cv_results = randomSearchCV_lgbm(df_rm)\n",
    "\n",
    "        model_path = os.path.join(model_dir, f\"lgbm_rm_{rid}.txt\")\n",
    "        model.booster_.save_model(model_path)\n",
    "\n",
    "        results.append({\"rm_id\": rid, \"model_path\": model_path})\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(os.path.join(model_dir, \"training_results.csv\"), index=False)\n",
    "    print(f\"\\nTraining completed. Results saved to {model_dir}\")\n",
    "    \n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f828e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast2025_per_rm(\n",
    "    forecast_start,\n",
    "    forecast_end,\n",
    "    active_rm_ids,\n",
    "    daily_receivals,\n",
    "    purchase_orders,\n",
    "    delays,\n",
    "    mapping,\n",
    "    receivals,\n",
    "    models_dir,\n",
    "    pred_path\n",
    "):\n",
    "    print(f\"Forecasting from {forecast_start.date()} to {forecast_end.date()} for {len(active_rm_ids)} rm_ids...\")\n",
    "\n",
    "    pred_rows = []\n",
    "    forecast_range = pd.date_range(forecast_start, forecast_end - pd.Timedelta(days=1))\n",
    "\n",
    "    # Group data for fast lookup\n",
    "    receivals_by_rm = {rid: df for rid, df in receivals.groupby(\"rm_id\")}\n",
    "    daily_by_rm = {rid: df for rid, df in daily_receivals.groupby(\"rm_id\")}\n",
    "    delays_by_rm = {rid: df for rid, df in delays.groupby(\"rm_id\")}\n",
    "\n",
    "    for rm_id in tqdm(active_rm_ids, desc=\"Forecasting per rm_id\"):\n",
    "        model_path = os.path.join(models_dir, f\"lgbm_rm_{rm_id}.txt\")\n",
    "\n",
    "        # Skip if model doesn’t exist\n",
    "        if not os.path.exists(model_path):\n",
    "            print(f\" No model found for rm_id {rm_id}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Load LightGBM model\n",
    "        model = lgb.Booster(model_file=model_path)\n",
    "\n",
    "        print(f\"Building features and forecasting for rm_id {rm_id}...\")\n",
    "\n",
    "        for date in forecast_range:\n",
    "            end_date = date.date() + pd.Timedelta(days=1)\n",
    "\n",
    "            feats = build_features(\n",
    "                rm_id,\n",
    "                forecast_start.date(),\n",
    "                end_date,\n",
    "                daily_by_rm.get(rm_id, pd.DataFrame()),\n",
    "                purchase_orders,\n",
    "                delays_by_rm.get(rm_id, pd.DataFrame()),\n",
    "                mapping,\n",
    "                receivals_by_rm.get(rm_id, pd.DataFrame())\n",
    "            )\n",
    "\n",
    "            # Prepare feature vector\n",
    "            X_test = pd.DataFrame([feats]).drop(columns=[\"forecast_start\", \"forecast_end\"], errors=\"ignore\")\n",
    "\n",
    "            # Predict\n",
    "            pred_cum_weight = model.predict(X_test)[0]\n",
    "            pred_cum_weight = max(pred_cum_weight, 0)  # no negative forecasts\n",
    "\n",
    "            pred_rows.append({\n",
    "                \"rm_id\": rm_id,\n",
    "                \"forecast_start_date\": forecast_start.date(),\n",
    "                \"forecast_end_date\": end_date,\n",
    "                \"cum_weight\": pred_cum_weight\n",
    "            })\n",
    "\n",
    "    pred_df = pd.DataFrame(pred_rows)\n",
    "    pred_df.to_csv(pred_path, index=False)\n",
    "    print(f\"\\nForecasting complete. Saved predictions to {pred_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f98d574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSubmission(pred_path, pred_map_path, sub_path):\n",
    "    forecast = pd.read_csv(pred_path)\n",
    "    mapping = pd.read_csv(pred_map_path)\n",
    "\n",
    "    merged = mapping.merge(\n",
    "        forecast,\n",
    "        on=[\"rm_id\", \"forecast_start_date\", \"forecast_end_date\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    # Replace missing cum_weight values with 0\n",
    "    merged[\"cum_weight\"] = merged[\"cum_weight\"].fillna(0)\n",
    "\n",
    "    # Prepare submission format\n",
    "    submission = merged[[\"ID\", \"cum_weight\"]].rename(columns={\"cum_weight\": \"predicted_weight\"})\n",
    "\n",
    "    # Save to CSV\n",
    "    submission.to_csv(sub_path, index=False)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3172c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1y/z5mwdhtx1vq9zh65ghs4txg40000gn/T/ipykernel_89890/2652312477.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  qty_rm_id_2025[\"delivery_date\"] = qty_rm_id_2025[\"delivery_date\"].dt.date\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecasting from 2025-01-01 to 2025-05-31 for 38 rm_ids...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forecasting per rm_id:   0%|          | 0/38 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building features and forecasting for rm_id 2161...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forecasting per rm_id:   3%|▎         | 1/38 [00:01<00:59,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building features and forecasting for rm_id 2124...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forecasting per rm_id:   5%|▌         | 2/38 [00:03<00:55,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building features and forecasting for rm_id 2125...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forecasting per rm_id:   8%|▊         | 3/38 [00:04<00:53,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building features and forecasting for rm_id 2123...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forecasting per rm_id:  11%|█         | 4/38 [00:06<00:52,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building features and forecasting for rm_id 2130...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forecasting per rm_id:  13%|█▎        | 5/38 [00:08<01:00,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building features and forecasting for rm_id 3781...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forecasting per rm_id:  16%|█▌        | 6/38 [00:10<00:55,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building features and forecasting for rm_id 3865...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forecasting per rm_id:  18%|█▊        | 7/38 [00:11<00:52,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building features and forecasting for rm_id 3121...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forecasting per rm_id:  21%|██        | 8/38 [00:13<00:49,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building features and forecasting for rm_id 3122...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forecasting per rm_id:  24%|██▎       | 9/38 [00:14<00:46,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building features and forecasting for rm_id 3123...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forecasting per rm_id:  26%|██▋       | 10/38 [00:16<00:44,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building features and forecasting for rm_id 3124...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forecasting per rm_id:  29%|██▉       | 11/38 [00:17<00:42,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building features and forecasting for rm_id 3125...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forecasting per rm_id:  32%|███▏      | 12/38 [00:19<00:41,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building features and forecasting for rm_id 3126...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forecasting per rm_id:  34%|███▍      | 13/38 [00:21<00:39,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building features and forecasting for rm_id 3201...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forecasting per rm_id:  37%|███▋      | 14/38 [00:22<00:38,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building features and forecasting for rm_id 3265...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forecasting per rm_id:  39%|███▉      | 15/38 [00:24<00:38,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building features and forecasting for rm_id 3282...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forecasting per rm_id:  42%|████▏     | 16/38 [00:26<00:35,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building features and forecasting for rm_id 3461...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forecasting per rm_id:  45%|████▍     | 17/38 [00:27<00:33,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building features and forecasting for rm_id 3701...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forecasting per rm_id:  47%|████▋     | 18/38 [00:28<00:31,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building features and forecasting for rm_id 4222...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forecasting per rm_id:  50%|█████     | 19/38 [00:30<00:29,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building features and forecasting for rm_id 4263...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forecasting per rm_id:  53%|█████▎    | 20/38 [00:32<00:27,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building features and forecasting for rm_id 2134...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forecasting per rm_id:  55%|█████▌    | 21/38 [00:33<00:27,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building features and forecasting for rm_id 2145...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forecasting per rm_id:  58%|█████▊    | 22/38 [00:35<00:25,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building features and forecasting for rm_id 2135...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forecasting per rm_id:  61%|██████    | 23/38 [00:37<00:25,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building features and forecasting for rm_id 3421...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forecasting per rm_id:  63%|██████▎   | 24/38 [00:38<00:23,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building features and forecasting for rm_id 3381...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forecasting per rm_id:  66%|██████▌   | 25/38 [00:40<00:20,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building features and forecasting for rm_id 2132...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forecasting per rm_id:  68%|██████▊   | 26/38 [00:42<00:19,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building features and forecasting for rm_id 2143...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forecasting per rm_id:  71%|███████   | 27/38 [00:43<00:18,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building features and forecasting for rm_id 2131...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forecasting per rm_id:  74%|███████▎  | 28/38 [00:45<00:16,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building features and forecasting for rm_id 2142...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forecasting per rm_id:  76%|███████▋  | 29/38 [00:47<00:15,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building features and forecasting for rm_id 2133...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forecasting per rm_id:  79%|███████▉  | 30/38 [00:48<00:13,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building features and forecasting for rm_id 2144...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forecasting per rm_id:  82%|████████▏ | 31/38 [00:50<00:12,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building features and forecasting for rm_id 2741...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forecasting per rm_id:  84%|████████▍ | 32/38 [00:52<00:10,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building features and forecasting for rm_id 4044...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forecasting per rm_id:  87%|████████▋ | 33/38 [00:53<00:08,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building features and forecasting for rm_id 4021...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forecasting per rm_id:  89%|████████▉ | 34/38 [00:55<00:06,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building features and forecasting for rm_id 3142...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forecasting per rm_id:  92%|█████████▏| 35/38 [00:57<00:04,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building features and forecasting for rm_id 3581...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forecasting per rm_id:  95%|█████████▍| 36/38 [00:58<00:03,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building features and forecasting for rm_id 4343...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forecasting per rm_id:  97%|█████████▋| 37/38 [01:00<00:01,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building features and forecasting for rm_id 4481...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forecasting per rm_id: 100%|██████████| 38/38 [01:02<00:00,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forecasting complete. Saved predictions to lgbm_per_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # == Prepare and build features and training set ==\n",
    "    receivals, purchase_orders, daily_receivals, qty_2025_rm_id, scheduled_rm_ids, delays, delay_stats, active_rm_ids = prepareData()\n",
    "    df_train = buildTrainSet(receivals, daily_receivals, purchase_orders, delays, scheduled_rm_ids, qty_2025_rm_id, \"trainingSet.csv\")\n",
    "    #df_train = pd.read_csv(\"trainingSet.csv\")\n",
    "\n",
    "    # == Train LGBM for each rm_id ==\n",
    "    models_dir = \"models_per_rm\"\n",
    "    train_all_rm_ids(df_train, model_dir=models_dir) \n",
    "\n",
    "    # == Forecast for 2025 ==\n",
    "    prediction_path = \"lgbm_per_test.csv\"\n",
    "    forecast2025_per_rm(FORECAST_START, FORECAST_END, scheduled_rm_ids, \n",
    "                                    daily_receivals, purchase_orders, delays, qty_2025_rm_id, receivals,\n",
    "                                    models_dir=models_dir, pred_path=prediction_path)\n",
    "    \n",
    "    # == Create submission == \n",
    "    createSubmission(prediction_path, \"data/prediction_mapping.csv\", \"submission1.csv\")\n",
    "    return\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Jupyter)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
