{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e338f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit\n",
    "import os\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf1300df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alembic==1.17.1\n",
      "anyio @ file:///home/conda/feedstock_root/build_artifacts/bld/rattler-build_anyio_1754315087/work\n",
      "appnope @ file:///home/conda/feedstock_root/build_artifacts/appnope_1733332318622/work\n",
      "argon2-cffi @ file:///home/conda/feedstock_root/build_artifacts/argon2-cffi_1749017159514/work\n",
      "argon2-cffi-bindings @ file:///Users/runner/miniforge3/conda-bld/argon2-cffi-bindings_1753994790109/work\n",
      "arrow @ file:///home/conda/feedstock_root/build_artifacts/arrow_1733584251875/work\n",
      "asttokens @ file:///home/conda/feedstock_root/build_artifacts/asttokens_1733250440834/work\n",
      "async-lru @ file:///home/conda/feedstock_root/build_artifacts/bld/rattler-build_async-lru_1742153708/work\n",
      "attrs @ file:///home/conda/feedstock_root/build_artifacts/attrs_1741918516150/work\n",
      "babel @ file:///home/conda/feedstock_root/build_artifacts/babel_1738490167835/work\n",
      "beautifulsoup4 @ file:///home/conda/feedstock_root/build_artifacts/beautifulsoup4_1756094236201/work\n",
      "bleach @ file:///home/conda/feedstock_root/build_artifacts/bld/rattler-build_bleach_1737382993/work\n",
      "Brotli @ file:///Users/runner/miniforge3/conda-bld/brotli-split_1756599273055/work\n",
      "cached-property @ file:///home/conda/feedstock_root/build_artifacts/cached_property_1615209429212/work\n",
      "certifi @ file:///home/conda/feedstock_root/build_artifacts/certifi_1754231422783/work/certifi\n",
      "cffi @ file:///Users/runner/miniforge3/conda-bld/cffi_1756808330057/work\n",
      "charset-normalizer @ file:///home/conda/feedstock_root/build_artifacts/charset-normalizer_1754767332901/work\n",
      "colorlog==6.10.1\n",
      "comm @ file:///home/conda/feedstock_root/build_artifacts/bld/rattler-build_comm_1753453984/work\n",
      "contourpy==1.3.3\n",
      "cycler==0.12.1\n",
      "debugpy @ file:///Users/runner/miniforge3/conda-bld/bld/rattler-build_debugpy_1756742018/work\n",
      "decorator @ file:///home/conda/feedstock_root/build_artifacts/decorator_1740384970518/work\n",
      "defusedxml @ file:///home/conda/feedstock_root/build_artifacts/defusedxml_1615232257335/work\n",
      "exceptiongroup @ file:///home/conda/feedstock_root/build_artifacts/exceptiongroup_1746947292760/work\n",
      "executing @ file:///home/conda/feedstock_root/build_artifacts/executing_1756729339227/work\n",
      "fastjsonschema @ file:///home/conda/feedstock_root/build_artifacts/bld/rattler-build_python-fastjsonschema_1755304154/work/dist\n",
      "fonttools==4.59.2\n",
      "fqdn @ file:///home/conda/feedstock_root/build_artifacts/fqdn_1733327382592/work/dist\n",
      "greenlet==3.2.4\n",
      "h11 @ file:///home/conda/feedstock_root/build_artifacts/h11_1745526374115/work\n",
      "h2 @ file:///home/conda/feedstock_root/build_artifacts/bld/rattler-build_h2_1756364871/work\n",
      "hpack @ file:///home/conda/feedstock_root/build_artifacts/hpack_1737618293087/work\n",
      "httpcore @ file:///home/conda/feedstock_root/build_artifacts/bld/rattler-build_httpcore_1745602916/work\n",
      "httpx @ file:///home/conda/feedstock_root/build_artifacts/httpx_1733663348460/work\n",
      "hyperframe @ file:///home/conda/feedstock_root/build_artifacts/hyperframe_1737618333194/work\n",
      "idna @ file:///home/conda/feedstock_root/build_artifacts/idna_1733211830134/work\n",
      "importlib_metadata @ file:///home/conda/feedstock_root/build_artifacts/bld/rattler-build_importlib-metadata_1747934053/work\n",
      "ipykernel @ file:///Users/runner/miniforge3/conda-bld/ipykernel_1754352890318/work\n",
      "ipython @ file:///home/conda/feedstock_root/build_artifacts/bld/rattler-build_ipython_1756474504/work\n",
      "ipython_pygments_lexers @ file:///home/conda/feedstock_root/build_artifacts/ipython_pygments_lexers_1737123620466/work\n",
      "ipywidgets @ file:///home/conda/feedstock_root/build_artifacts/ipywidgets_1746454582739/work\n",
      "isoduration @ file:///home/conda/feedstock_root/build_artifacts/isoduration_1733493628631/work/dist\n",
      "jedi @ file:///home/conda/feedstock_root/build_artifacts/jedi_1733300866624/work\n",
      "Jinja2 @ file:///home/conda/feedstock_root/build_artifacts/jinja2_1741263328855/work\n",
      "joblib @ file:///home/conda/feedstock_root/build_artifacts/joblib_1756321760188/work\n",
      "json5 @ file:///home/conda/feedstock_root/build_artifacts/json5_1755034879854/work\n",
      "jsonpointer @ file:///Users/runner/miniforge3/conda-bld/jsonpointer_1756754198441/work\n",
      "jsonschema @ file:///home/conda/feedstock_root/build_artifacts/bld/rattler-build_jsonschema_1755595646/work\n",
      "jsonschema-specifications @ file:///tmp/tmpuvkyqc9y/src\n",
      "jupyter @ file:///home/conda/feedstock_root/build_artifacts/jupyter_1733818543322/work\n",
      "jupyter-console @ file:///home/conda/feedstock_root/build_artifacts/jupyter_console_1733817997778/work\n",
      "jupyter-events @ file:///home/conda/feedstock_root/build_artifacts/bld/rattler-build_jupyter_events_1738765986/work\n",
      "jupyter-lsp @ file:///home/conda/feedstock_root/build_artifacts/bld/rattler-build_jupyter-lsp_1756388269/work/jupyter-lsp\n",
      "jupyter_client @ file:///home/conda/feedstock_root/build_artifacts/jupyter_client_1733440914442/work\n",
      "jupyter_core @ file:///home/conda/feedstock_root/build_artifacts/jupyter_core_1748333051527/work\n",
      "jupyter_server @ file:///home/conda/feedstock_root/build_artifacts/bld/rattler-build_jupyter_server_1755870522/work\n",
      "jupyter_server_terminals @ file:///home/conda/feedstock_root/build_artifacts/jupyter_server_terminals_1733427956852/work\n",
      "jupyterlab @ file:///home/conda/feedstock_root/build_artifacts/jupyterlab_1756911582509/work\n",
      "jupyterlab_pygments @ file:///home/conda/feedstock_root/build_artifacts/jupyterlab_pygments_1733328101776/work\n",
      "jupyterlab_server @ file:///home/conda/feedstock_root/build_artifacts/jupyterlab_server_1733599573484/work\n",
      "jupyterlab_widgets @ file:///home/conda/feedstock_root/build_artifacts/jupyterlab_widgets_1746450771080/work\n",
      "kiwisolver==1.4.9\n",
      "lark @ file:///home/conda/feedstock_root/build_artifacts/lark_1734709323538/work\n",
      "lightgbm==4.6.0\n",
      "Mako==1.3.10\n",
      "MarkupSafe @ file:///Users/runner/miniforge3/conda-bld/markupsafe_1733219683650/work\n",
      "matplotlib==3.10.6\n",
      "matplotlib-inline @ file:///home/conda/feedstock_root/build_artifacts/matplotlib-inline_1733416936468/work\n",
      "mistune @ file:///home/conda/feedstock_root/build_artifacts/bld/rattler-build_mistune_1756495311/work\n",
      "nbclient @ file:///home/conda/feedstock_root/build_artifacts/nbclient_1734628800805/work\n",
      "nbconvert @ file:///home/conda/feedstock_root/build_artifacts/bld/rattler-build_nbconvert-core_1738067871/work\n",
      "nbformat @ file:///home/conda/feedstock_root/build_artifacts/nbformat_1733402752141/work\n",
      "nest_asyncio @ file:///home/conda/feedstock_root/build_artifacts/nest-asyncio_1733325553580/work\n",
      "notebook @ file:///home/conda/feedstock_root/build_artifacts/notebook_1754403910043/work\n",
      "notebook_shim @ file:///home/conda/feedstock_root/build_artifacts/notebook-shim_1733408315203/work\n",
      "numpy==2.3.2\n",
      "optuna==4.5.0\n",
      "overrides @ file:///home/conda/feedstock_root/build_artifacts/overrides_1734587627321/work\n",
      "packaging @ file:///home/conda/feedstock_root/build_artifacts/bld/rattler-build_packaging_1745345660/work\n",
      "pandas @ file:///Users/runner/miniforge3/conda-bld/pandas_1755779011466/work\n",
      "pandocfilters @ file:///home/conda/feedstock_root/build_artifacts/pandocfilters_1631603243851/work\n",
      "parso @ file:///home/conda/feedstock_root/build_artifacts/bld/rattler-build_parso_1755974222/work\n",
      "pexpect @ file:///home/conda/feedstock_root/build_artifacts/pexpect_1733301927746/work\n",
      "pickleshare @ file:///home/conda/feedstock_root/build_artifacts/pickleshare_1733327343728/work\n",
      "pillow==11.3.0\n",
      "platformdirs @ file:///home/conda/feedstock_root/build_artifacts/bld/rattler-build_platformdirs_1756227402/work\n",
      "prometheus_client @ file:///home/conda/feedstock_root/build_artifacts/prometheus_client_1748896729786/work\n",
      "prompt_toolkit @ file:///home/conda/feedstock_root/build_artifacts/prompt-toolkit_1756321756983/work\n",
      "psutil @ file:///Users/runner/miniforge3/conda-bld/psutil_1755851346434/work\n",
      "ptyprocess @ file:///home/conda/feedstock_root/build_artifacts/ptyprocess_1733302279685/work/dist/ptyprocess-0.7.0-py2.py3-none-any.whl#sha256=92c32ff62b5fd8cf325bec5ab90d7be3d2a8ca8c8a3813ff487a8d2002630d1f\n",
      "pure_eval @ file:///home/conda/feedstock_root/build_artifacts/pure_eval_1733569405015/work\n",
      "pycparser @ file:///home/conda/feedstock_root/build_artifacts/bld/rattler-build_pycparser_1733195786/work\n",
      "Pygments @ file:///home/conda/feedstock_root/build_artifacts/pygments_1750615794071/work\n",
      "pyobjc-core @ file:///Users/runner/miniforge3/conda-bld/pyobjc-core_1756812783073/work\n",
      "pyobjc-framework-Cocoa @ file:///Users/runner/miniforge3/conda-bld/pyobjc-framework-cocoa_1756823866521/work\n",
      "pyparsing==3.2.3\n",
      "PySocks @ file:///home/conda/feedstock_root/build_artifacts/pysocks_1733217236728/work\n",
      "python-dateutil @ file:///home/conda/feedstock_root/build_artifacts/bld/rattler-build_python-dateutil_1751104122/work\n",
      "python-json-logger @ file:///home/conda/feedstock_root/build_artifacts/python-json-logger_1677079630776/work\n",
      "pytz @ file:///home/conda/feedstock_root/build_artifacts/pytz_1742920838005/work\n",
      "PyYAML @ file:///Users/runner/miniforge3/conda-bld/pyyaml_1737454694178/work\n",
      "pyzmq @ file:///Users/runner/miniforge3/conda-bld/bld/rattler-build_pyzmq_1757116354/work\n",
      "referencing @ file:///home/conda/feedstock_root/build_artifacts/bld/rattler-build_referencing_1737836872/work\n",
      "requests @ file:///home/conda/feedstock_root/build_artifacts/requests_1755614211359/work\n",
      "rfc3339_validator @ file:///home/conda/feedstock_root/build_artifacts/rfc3339-validator_1733599910982/work\n",
      "rfc3986-validator @ file:///home/conda/feedstock_root/build_artifacts/rfc3986-validator_1598024191506/work\n",
      "rfc3987-syntax @ file:///home/conda/feedstock_root/build_artifacts/bld/rattler-build_rfc3987-syntax_1752876729/work\n",
      "rpds-py @ file:///Users/runner/miniforge3/conda-bld/bld/rattler-build_rpds-py_1756737583/work\n",
      "scikit-learn @ file:///Users/runner/miniforge3/conda-bld/scikit-learn_1752825759144/work/dist/scikit_learn-1.7.1-cp311-cp311-macosx_10_13_x86_64.whl#sha256=47f013abfef517d312dec9983081858addbca2e5b9afabdfce9c09cda969f70d\n",
      "scipy==1.16.1\n",
      "seaborn==0.13.2\n",
      "Send2Trash @ file:///Users/runner/miniforge3/conda-bld/send2trash_1733322099476/work\n",
      "six @ file:///home/conda/feedstock_root/build_artifacts/bld/rattler-build_six_1753199211/work\n",
      "sniffio @ file:///home/conda/feedstock_root/build_artifacts/sniffio_1733244044561/work\n",
      "soupsieve @ file:///home/conda/feedstock_root/build_artifacts/soupsieve_1756330469801/work\n",
      "SQLAlchemy==2.0.44\n",
      "stack_data @ file:///home/conda/feedstock_root/build_artifacts/stack_data_1733569443808/work\n",
      "terminado @ file:///Users/runner/miniforge3/conda-bld/terminado_1710263781917/work\n",
      "threadpoolctl @ file:///home/conda/feedstock_root/build_artifacts/threadpoolctl_1741878222898/work\n",
      "tinycss2 @ file:///home/conda/feedstock_root/build_artifacts/tinycss2_1729802851396/work\n",
      "tomli @ file:///home/conda/feedstock_root/build_artifacts/bld/rattler-build_tomli_1753796677/work\n",
      "tornado @ file:///Users/runner/miniforge3/conda-bld/tornado_1756854937506/work\n",
      "tqdm==4.67.1\n",
      "traitlets @ file:///home/conda/feedstock_root/build_artifacts/traitlets_1733367359838/work\n",
      "types-python-dateutil @ file:///home/conda/feedstock_root/build_artifacts/types-python-dateutil_1755865529509/work\n",
      "typing_extensions @ file:///home/conda/feedstock_root/build_artifacts/bld/rattler-build_typing_extensions_1756220668/work\n",
      "typing_utils @ file:///home/conda/feedstock_root/build_artifacts/typing_utils_1733331286120/work\n",
      "tzdata @ file:///home/conda/feedstock_root/build_artifacts/python-tzdata_1742745135198/work\n",
      "uri-template @ file:///home/conda/feedstock_root/build_artifacts/uri-template_1733323593477/work/dist\n",
      "urllib3 @ file:///home/conda/feedstock_root/build_artifacts/urllib3_1750271362675/work\n",
      "wcwidth @ file:///home/conda/feedstock_root/build_artifacts/wcwidth_1733231326287/work\n",
      "webcolors @ file:///home/conda/feedstock_root/build_artifacts/webcolors_1733359735138/work\n",
      "webencodings @ file:///home/conda/feedstock_root/build_artifacts/webencodings_1733236011802/work\n",
      "websocket-client @ file:///home/conda/feedstock_root/build_artifacts/websocket-client_1733157342724/work\n",
      "widgetsnbextension @ file:///home/conda/feedstock_root/build_artifacts/widgetsnbextension_1744291053367/work\n",
      "xgboost==3.0.5\n",
      "zipp @ file:///home/conda/feedstock_root/build_artifacts/zipp_1749421620841/work\n",
      "zstandard==0.24.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21a9eb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "RECEIVALS_PATH = \"data/kernel/receivals.csv\"\n",
    "PO_PATH = \"data/kernel/purchase_orders.csv\"\n",
    "MAT_PATH = \"data/extended/materials.csv\"\n",
    "\n",
    "FORECAST_START = pd.to_datetime(\"2025-01-01\", utc=True)\n",
    "FORECAST_END = pd.to_datetime(\"2025-05-31\", utc=True)\n",
    "\n",
    "LAST_RECEIVAL_DATE = pd.Timestamp(\"2024-12-19\", tz=\"UTC\")\n",
    "\n",
    "def prepareData(receivals_path=RECEIVALS_PATH, po_path=PO_PATH, mat_path=MAT_PATH):\n",
    "    \n",
    "    # === Clean receivals ===\n",
    "    receivals = pd.read_csv(receivals_path)\n",
    "    receivals = receivals.dropna(subset=[\"rm_id\", \"purchase_order_id\", \"product_id\"])\n",
    "    receivals[\"rm_id\"] = receivals[\"rm_id\"].astype(int)\n",
    "    receivals[\"purchase_order_id\"] = receivals[\"purchase_order_id\"].astype(int)\n",
    "    receivals[\"product_id\"] = receivals[\"product_id\"].astype(int)\n",
    "    receivals[\"date_arrival\"] = pd.to_datetime(receivals[\"date_arrival\"], utc=True)\n",
    "\n",
    "    # == Clean purchase orders ==\n",
    "    purchase_orders = pd.read_csv(po_path)\n",
    "    purchase_orders = purchase_orders[purchase_orders[\"quantity\"] > 0] # Remove negative and 0 quantity orders\n",
    "    purchase_orders[\"delivery_date\"] = pd.to_datetime(purchase_orders[\"delivery_date\"], utc=True)\n",
    "\n",
    "    # == Clean materials ==\n",
    "    materials = pd.read_csv(mat_path)\n",
    "    materials = materials.dropna(subset=[\"product_id\", \"rm_id\"])\n",
    "    materials[\"product_id\"] = materials[\"product_id\"].astype(int)\n",
    "    materials[\"rm_id\"] = materials[\"rm_id\"].astype(int)\n",
    "\n",
    "    # Find rm_ids scheduled for 2025\n",
    "    po_2025 = purchase_orders[purchase_orders[\"delivery_date\"] >= FORECAST_START].copy()\n",
    "    po_2025 = po_2025.sort_values(by=\"delivery_date\")\n",
    "    materials_unique = materials.drop_duplicates(subset=[\"rm_id\", \"product_id\"])\n",
    "\n",
    "    merged_po2025_mat = po_2025.merge(materials_unique, on=[\"product_id\"], how=\"left\")\n",
    "\n",
    "    one_year_before = pd.to_datetime(\"2024-01-01\", utc=True) # Only rm_ids that had a delivery in 2024, if not they are likely out of production\n",
    "    active_rm_ids = receivals.loc[receivals[\"date_arrival\"] >= one_year_before, \"rm_id\"].unique()\n",
    "\n",
    "    merged_active = merged_po2025_mat[merged_po2025_mat[\"rm_id\"].isin(active_rm_ids)].copy()\n",
    "    scheduled_active_rm_ids = merged_active[\"rm_id\"].unique() # 38 found to be active with this method\n",
    "\n",
    "    # Find scheduled quantity for all active rm_ids/product_ids in 2025.\n",
    "    qty_rm_id_2025 = merged_active[[\"rm_id\", \"product_id\", \"delivery_date\", \"quantity\"]]\n",
    "    qty_rm_id_2025[\"delivery_date\"] = qty_rm_id_2025[\"delivery_date\"].dt.date\n",
    "\n",
    "    # Get daily total receivals per rm_id and mean/std(delay) for each rm_id\n",
    "    merged = pd.merge(purchase_orders, receivals, on=[\"purchase_order_id\", \"purchase_order_item_no\"], suffixes=(\"_receival\", \"_order\"))\n",
    "    merged = merged.sort_values(by=\"date_arrival\")\n",
    "\n",
    "    merged[\"delay\"] = (merged[\"date_arrival\"] - merged[\"delivery_date\"]).dt.days\n",
    "    merged[\"date_arrival\"] = merged[\"date_arrival\"].dt.date\n",
    "    merged[\"delivery_date\"] = merged[\"delivery_date\"].dt.date\n",
    "\n",
    "    daily_receivals = merged.groupby([\"rm_id\", \"date_arrival\"], as_index=False)[\"net_weight\"].sum()\n",
    "    daily_receivals[\"date_arrival\"] = pd.to_datetime(daily_receivals[\"date_arrival\"], utc=True)\n",
    "\n",
    "    delays = merged[[\"rm_id\", \"date_arrival\", \"delay\"]]\n",
    "\n",
    "    delay_stats = merged.groupby(\"rm_id\")[\"delay\"].agg([\"mean\", \"std\"]).reset_index()\n",
    "\n",
    "    purchase_orders[\"delivery_date\"] = purchase_orders[\"delivery_date\"].dt.date\n",
    "    receivals[\"date_arrival\"] = receivals[\"date_arrival\"].dt.date\n",
    "    daily_receivals[\"date_arrival\"] = daily_receivals[\"date_arrival\"].dt.date \n",
    "\n",
    "    return receivals, purchase_orders, daily_receivals, qty_rm_id_2025, scheduled_active_rm_ids, delays, delay_stats, active_rm_ids\n",
    "\n",
    "def getExpectedQty(rm_id, purchase_orders, mapping, forecast_start, forecast_end):\n",
    "    prod_id = getProdId(rm_id, mapping)\n",
    "    if prod_id is None:\n",
    "        return 0.0\n",
    "    expected_qty_product_id = purchase_orders.loc[\n",
    "        (purchase_orders[\"product_id\"] == prod_id) &\n",
    "        (purchase_orders[\"delivery_date\"] >= forecast_start) &\n",
    "        (purchase_orders[\"delivery_date\"] <= forecast_end),\n",
    "        \"quantity\"\n",
    "    ].sum()\n",
    "\n",
    "    return expected_qty_product_id\n",
    "\n",
    "def getProdId(rm_id, mapping):\n",
    "    row = mapping.loc[mapping[\"rm_id\"] == rm_id]\n",
    "    if row.empty:\n",
    "        return None\n",
    "    return row[\"product_id\"].iloc[0]\n",
    "\n",
    "def prob_rm_id(rm_id, mapping, receivals, forecast_start, days):\n",
    "    # Find prob of\n",
    "    prod_id = getProdId(rm_id, mapping)\n",
    "    check_from = (forecast_start - pd.Timedelta(days=days))\n",
    "    recent_prodId = receivals.loc[\n",
    "        (receivals[\"product_id\"] == prod_id) & # can be a problem with float vs int here. Maybe drop NaNs in receivals and initfy\n",
    "        (receivals[\"date_arrival\"] >= check_from) &\n",
    "        (receivals[\"date_arrival\"] < forecast_start)\n",
    "    ]\n",
    "    \n",
    "    if recent_prodId.empty:\n",
    "        return 1.0\n",
    "     \n",
    "    total_count = len(recent_prodId)\n",
    "    rm_count = (recent_prodId[\"rm_id\"] == rm_id).sum()\n",
    "    return rm_count/total_count\n",
    "\n",
    "def get_exp_qty_rm_id(rm_id, mapping, receivals, purchase_orders, forecast_start, forecast_end, histDays):\n",
    "    totExpectedQty = getExpectedQty(rm_id, purchase_orders, mapping, forecast_start, forecast_end)\n",
    "    probRmID = prob_rm_id(rm_id, mapping, receivals, forecast_start, histDays)\n",
    "    expectQty = totExpectedQty*probRmID\n",
    "    bufferQty = totExpectedQty-expectQty\n",
    "    return expectQty, bufferQty\n",
    "\n",
    "def build_features(rm_id, forecast_start, forecast_end, daily_receivals, purchase_orders, delays, mapping, receivals):\n",
    "    hist_delays = delays[delays[\"date_arrival\"] < forecast_start]\n",
    "    hist_daily_receivals = daily_receivals[daily_receivals[\"date_arrival\"] < forecast_start]\n",
    "    \n",
    "    recent_from_150 = (forecast_start - pd.Timedelta(days=150))\n",
    "    recent_from_60 = (forecast_start - pd.Timedelta(days=60))\n",
    "    recent_from_30 = (forecast_start - pd.Timedelta(days=30))\n",
    "    \n",
    "    recent_150 = daily_receivals[(daily_receivals[\"date_arrival\"] >= recent_from_150) \n",
    "                           & (daily_receivals[\"date_arrival\"] < forecast_start)].copy()\n",
    "    \n",
    "    recent_60 = daily_receivals[(daily_receivals[\"date_arrival\"] >= recent_from_60) \n",
    "                           & (daily_receivals[\"date_arrival\"] < forecast_start)].copy()\n",
    "    \n",
    "    recent_30 = daily_receivals[(daily_receivals[\"date_arrival\"] >= recent_from_30) \n",
    "                           & (daily_receivals[\"date_arrival\"] < forecast_start)].copy()\n",
    "    \n",
    "\n",
    "    full_date_range_150 = pd.date_range(\n",
    "        start=recent_from_150, \n",
    "        end=(forecast_start - pd.Timedelta(days=1)), \n",
    "        freq=\"D\"\n",
    "    )\n",
    "\n",
    "    full_date_range_60 = pd.date_range(\n",
    "        start=recent_from_60, \n",
    "        end=(forecast_start - pd.Timedelta(days=1)), \n",
    "        freq=\"D\"\n",
    "    )\n",
    "\n",
    "    full_date_range_30 = pd.date_range(\n",
    "        start=recent_from_30, \n",
    "        end=(forecast_start - pd.Timedelta(days=1)), \n",
    "        freq=\"D\"\n",
    "    )\n",
    "\n",
    "    recent_150_full = (\n",
    "        recent_150\n",
    "        .set_index(\"date_arrival\")\n",
    "        .reindex(full_date_range_150, fill_value=0)\n",
    "        .rename_axis(\"date_arrival\")\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    recent_60_full = (\n",
    "        recent_60\n",
    "        .set_index(\"date_arrival\")\n",
    "        .reindex(full_date_range_60, fill_value=0)\n",
    "        .rename_axis(\"date_arrival\")\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    recent_30_full = (\n",
    "        recent_30\n",
    "        .set_index(\"date_arrival\")\n",
    "        .reindex(full_date_range_30, fill_value=0)\n",
    "        .rename_axis(\"date_arrival\")\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    recent_150_full[\"rm_id\"] = rm_id\n",
    "    recent_60_full[\"rm_id\"] = rm_id\n",
    "    recent_30_full[\"rm_id\"] = rm_id\n",
    "\n",
    "    total_expected_quantity = purchase_orders.loc[\n",
    "        (purchase_orders[\"delivery_date\"] >= forecast_start) &\n",
    "        (purchase_orders[\"delivery_date\"] <= forecast_end),\n",
    "        \"quantity\"\n",
    "    ].sum()\n",
    "\n",
    "    mean_daily_weight_150 = recent_150_full[\"net_weight\"].mean()\n",
    "    mean_daily_weight_60 = recent_60_full[\"net_weight\"].mean()\n",
    "    mean_daily_weight_30 = recent_30_full[\"net_weight\"].mean()\n",
    "    window_length = (forecast_end-forecast_start).days + 1\n",
    "\n",
    "    expectQty_rm, bufferQty_rm = get_exp_qty_rm_id(rm_id, mapping, receivals, purchase_orders, forecast_start, forecast_end, 150)\n",
    "\n",
    "    last_delivery = hist_daily_receivals[\"date_arrival\"].max()\n",
    "    if pd.isna(last_delivery):\n",
    "        days_since_last_delivery = np.nan\n",
    "    else:\n",
    "        days_since_last_delivery = (forecast_start - last_delivery).days\n",
    "\n",
    "    features = {\n",
    "        \"rm_id\": rm_id,\n",
    "        \"forecast_start\": forecast_start,\n",
    "        \"forecast_end\": forecast_end,\n",
    "        \"window_length\": window_length,\n",
    "        \"mean_daily_weight_150\": mean_daily_weight_150,\n",
    "        \"mean_daily_weight_60\": mean_daily_weight_60,\n",
    "        \"mean_daily_weight_30\": mean_daily_weight_30,\n",
    "        \"days_since_last_delivery\": days_since_last_delivery,\n",
    "        \"num_deliveries_last_150\": len(recent_150),\n",
    "        \"avg_delivery_time\": hist_delays[\"delay\"].mean(),\n",
    "        \"std_delivery_time\": hist_delays[\"delay\"].std(),\n",
    "        \"total_expected_qty\": total_expected_quantity,\n",
    "        \"expected_qty_rm_id\": expectQty_rm,\n",
    "        \"buffer_qty\": bufferQty_rm\n",
    "\n",
    "    }\n",
    "\n",
    "    # Can make month and day etc on forecast_end\n",
    "\n",
    "    return features\n",
    "\n",
    "def buildTrainSet(receivals, daily_receivals, purchase_orders, delays, active_rm_ids, mapping, output_path):\n",
    "    train_rows = []\n",
    "    window_lengths = range(1, 151) \n",
    "    start_dates = pd.date_range(pd.to_datetime(\"2018-01-01\", utc=True), FORECAST_START, freq=\"14D\")  # slide every 14 days\n",
    "    \n",
    "    receivals_by_rm = {rid: df for rid, df in receivals.groupby(\"rm_id\")}\n",
    "    daily_by_rm = {rid: df for rid, df in daily_receivals.groupby(\"rm_id\")}\n",
    "    delays_by_rm = {rid: df for rid, df in delays.groupby(\"rm_id\")}\n",
    "    \n",
    "    for rm_id in tqdm(active_rm_ids):\n",
    "        print(\"Processing rm_id: \", rm_id)\n",
    "\n",
    "        for wl in tqdm(window_lengths):\n",
    "            for start in start_dates:\n",
    "                end = start + pd.Timedelta(days=wl - 1)\n",
    "                if end >= LAST_RECEIVAL_DATE: # last date in receivals\n",
    "                    break\n",
    "                feats = build_features(rm_id, start.date(), end.date(), \n",
    "                                       daily_by_rm.get(rm_id, pd.DataFrame()), \n",
    "                                       purchase_orders, \n",
    "                                       delays_by_rm.get(rm_id, pd.DataFrame()), \n",
    "                                       mapping, receivals_by_rm.get(rm_id, pd.DataFrame()))\n",
    "\n",
    "                cum_weight = daily_receivals.loc[\n",
    "                    (daily_receivals[\"rm_id\"] == rm_id) &\n",
    "                    (daily_receivals[\"date_arrival\"] >= start.date()) &\n",
    "                    (daily_receivals[\"date_arrival\"] <= end.date()),\n",
    "                    \"net_weight\"\n",
    "                ].sum()\n",
    "\n",
    "                feats[\"cum_weight\"] = cum_weight\n",
    "                train_rows.append(feats)\n",
    "\n",
    "    df_train = pd.DataFrame(train_rows)\n",
    "\n",
    "    df_train.to_csv(output_path, index=False)\n",
    "    \n",
    "    return df_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ee367f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_loss(y_true, y_pred, alpha=0.2):\n",
    "    err = y_true - y_pred\n",
    "    return np.mean(np.maximum(alpha * err, (alpha - 1) * err))\n",
    "\n",
    "def objective(trial, X_train, y_train, X_valid, y_valid):\n",
    "    params = dict(\n",
    "        objective=\"quantile\",\n",
    "        alpha=0.2,\n",
    "        learning_rate=trial.suggest_float(\"learning_rate\", 0.001, 0.05, log=True),\n",
    "        num_leaves=trial.suggest_int(\"num_leaves\", 15, 127, log=True),\n",
    "        max_depth=trial.suggest_int(\"max_depth\", 3, 9),\n",
    "        subsample=trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        colsample_bytree=trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        reg_alpha=trial.suggest_float(\"reg_alpha\", 0.0, 1.0),\n",
    "        reg_lambda=trial.suggest_float(\"reg_lambda\", 0.0, 1.0),\n",
    "        min_child_samples=trial.suggest_int(\"min_child_samples\", 10, 50),\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    model = lgb.LGBMRegressor(**params, n_estimators=5000)\n",
    "\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        eval_metric=\"quantile\",\n",
    "        categorical_feature=[\"rm_id\"],\n",
    "        callbacks=[lgb.early_stopping(100, verbose=False)]\n",
    "    )\n",
    "\n",
    "    preds = model.predict(X_valid)\n",
    "    return quantile_loss(y_valid, preds, alpha=0.2)\n",
    "\n",
    "\n",
    "def train_global_model_lgbm_optuna(df_train, model_dir):\n",
    "\n",
    "    # Define training/validation split by time\n",
    "    cutoff = LAST_RECEIVAL_DATE - pd.Timedelta(days=150)\n",
    "    df_train[\"forecast_start\"] = pd.to_datetime(df_train[\"forecast_start\"], utc=True)\n",
    "    df_train[\"forecast_end\"] = pd.to_datetime(df_train[\"forecast_end\"], utc=True)\n",
    "\n",
    "    train = df_train[df_train[\"forecast_end\"] < cutoff]\n",
    "    valid = df_train[df_train[\"forecast_start\"] >= cutoff]\n",
    "\n",
    "    X_train = train.drop(columns=[\"cum_weight\", \"forecast_start\", \"forecast_end\"])\n",
    "    y_train = train[\"cum_weight\"]\n",
    "    X_valid = valid.drop(columns=[\"cum_weight\", \"forecast_start\", \"forecast_end\"])\n",
    "    y_valid = valid[\"cum_weight\"]\n",
    "\n",
    "    # === Optuna tuning ===\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(lambda trial: objective(trial, X_train, y_train, X_valid, y_valid), n_trials=10)\n",
    "    best_params = study.best_params\n",
    "    print(\"Best params:\", best_params)\n",
    "\n",
    "    # Add fixed parameters\n",
    "    best_params.update({\n",
    "        \"objective\": \"quantile\",\n",
    "        \"alpha\": 0.2,\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1,\n",
    "        \"verbosity\": -1\n",
    "    })\n",
    "\n",
    "    # === Retrain model with best params ===\n",
    "    best_model = lgb.LGBMRegressor(**best_params, n_estimators=1000)\n",
    "    best_model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        eval_metric=\"quantile\",\n",
    "        categorical_feature=[\"rm_id\"],\n",
    "        callbacks=[lgb.early_stopping(200)]\n",
    "    )\n",
    "\n",
    "    best_iteration = best_model.best_iteration_\n",
    "    print(f\"Best iteration found: {best_iteration}\")\n",
    "\n",
    "    # === Train final model on all data ===\n",
    "    X_full = df_train.drop(columns=[\"cum_weight\", \"forecast_start\", \"forecast_end\"])\n",
    "    y_full = df_train[\"cum_weight\"]\n",
    "\n",
    "    final_model = lgb.LGBMRegressor(**best_params, n_estimators=best_iteration)\n",
    "    final_model.fit(X_full, y_full, categorical_feature=[\"rm_id\"])\n",
    "\n",
    "    final_model.booster_.save_model(model_dir)\n",
    "    return final_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f828e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast2025(model, forecast_start, forecast_end, active_rm_ids, daily_receivals, purchase_orders, delays,\n",
    "             mapping, receivals, pred_path):\n",
    "\n",
    "    print(\"Forecasting for 2025!\")\n",
    "    pred_rows = []\n",
    "\n",
    "    forecast_range = pd.date_range(forecast_start, forecast_end - pd.Timedelta(days=1))\n",
    "\n",
    "    receivals_by_rm = {rid: df for rid, df in receivals.groupby(\"rm_id\")}\n",
    "    daily_by_rm = {rid: df for rid, df in daily_receivals.groupby(\"rm_id\")}\n",
    "    delays_by_rm = {rid: df for rid, df in delays.groupby(\"rm_id\")}\n",
    "    \n",
    "    for rm_id in tqdm(active_rm_ids):\n",
    "        print(\"Building features for rm_id \", rm_id)\n",
    "        # Build features for the given rm_id and forecast window\n",
    "        for date in forecast_range:\n",
    "            end_date = date.date() + pd.Timedelta(days=1)\n",
    "            feats = build_features(rm_id, forecast_start.date(), end_date,\n",
    "                                                    daily_by_rm.get(rm_id, pd.DataFrame()), \n",
    "                                                    purchase_orders, \n",
    "                                                    delays_by_rm.get(rm_id, pd.DataFrame()), \n",
    "                                                    mapping, \n",
    "                                                    receivals_by_rm.get(rm_id, pd.DataFrame()))\n",
    "            X_test = pd.DataFrame([feats]).drop(columns=[\"forecast_start\", \"forecast_end\"])\n",
    "\n",
    "            # Predict using trained model\n",
    "            pred_cum_weight = model.predict(X_test)[0]\n",
    "            pred_cum_weight = max(pred_cum_weight, 0)\n",
    "\n",
    "            pred_rows.append({\n",
    "                \"rm_id\": rm_id,\n",
    "                \"forecast_start_date\": forecast_start.date(),\n",
    "                \"forecast_end_date\": end_date,\n",
    "                \"cum_weight\": pred_cum_weight\n",
    "            })\n",
    "\n",
    "\n",
    "    pred_df = pd.DataFrame(pred_rows)\n",
    "\n",
    "    pred_df.to_csv(pred_path)\n",
    "        \n",
    "    return pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f98d574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSubmission(pred_path, pred_map_path, sub_path):\n",
    "    forecast = pd.read_csv(pred_path)\n",
    "    mapping = pd.read_csv(pred_map_path)\n",
    "\n",
    "    merged = mapping.merge(\n",
    "        forecast,\n",
    "        on=[\"rm_id\", \"forecast_start_date\", \"forecast_end_date\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    # Replace missing cum_weight values with 0\n",
    "    merged[\"cum_weight\"] = merged[\"cum_weight\"].fillna(0)\n",
    "\n",
    "    # Prepare submission format\n",
    "    submission = merged[[\"ID\", \"cum_weight\"]].rename(columns={\"cum_weight\": \"predicted_weight\"})\n",
    "\n",
    "    # Save to CSV\n",
    "    submission.to_csv(sub_path, index=False)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3172c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1y/z5mwdhtx1vq9zh65ghs4txg40000gn/T/ipykernel_4684/2652312477.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  qty_rm_id_2025[\"delivery_date\"] = qty_rm_id_2025[\"delivery_date\"].dt.date\n",
      "  0%|          | 0/38 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing rm_id:  2161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|â–         | 6/150 [00:15<06:08,  2.56s/it]\n",
      "  0%|          | 0/38 [00:15<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     21\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmain\u001b[39m():\n\u001b[32m      2\u001b[39m     \u001b[38;5;66;03m# == Prepare and build features and training set ==\u001b[39;00m\n\u001b[32m      3\u001b[39m     receivals, purchase_orders, daily_receivals, qty_2025_rm_id, scheduled_rm_ids, delays, delay_stats, active_rm_ids = prepareData()\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     df_train = \u001b[43mbuildTrainSet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreceivals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdaily_receivals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpurchase_orders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduled_rm_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqty_2025_rm_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrainingSet.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     \u001b[38;5;66;03m#df_train = pd.read_csv(\"trainingSet.csv\")\u001b[39;00m\n\u001b[32m      6\u001b[39m \n\u001b[32m      7\u001b[39m     \u001b[38;5;66;03m# == Train global LGBM ==\u001b[39;00m\n\u001b[32m      8\u001b[39m     model_dir = \u001b[33m\"\u001b[39m\u001b[33mlgbm_global_optuna.txt\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 243\u001b[39m, in \u001b[36mbuildTrainSet\u001b[39m\u001b[34m(receivals, daily_receivals, purchase_orders, delays, active_rm_ids, mapping, output_path)\u001b[39m\n\u001b[32m    233\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    234\u001b[39m feats = build_features(rm_id, start.date(), end.date(), \n\u001b[32m    235\u001b[39m                        daily_by_rm.get(rm_id, pd.DataFrame()), \n\u001b[32m    236\u001b[39m                        purchase_orders, \n\u001b[32m    237\u001b[39m                        delays_by_rm.get(rm_id, pd.DataFrame()), \n\u001b[32m    238\u001b[39m                        mapping, receivals_by_rm.get(rm_id, pd.DataFrame()))\n\u001b[32m    240\u001b[39m cum_weight = daily_receivals.loc[\n\u001b[32m    241\u001b[39m     (daily_receivals[\u001b[33m\"\u001b[39m\u001b[33mrm_id\u001b[39m\u001b[33m\"\u001b[39m] == rm_id) &\n\u001b[32m    242\u001b[39m     (daily_receivals[\u001b[33m\"\u001b[39m\u001b[33mdate_arrival\u001b[39m\u001b[33m\"\u001b[39m] >= start.date()) &\n\u001b[32m--> \u001b[39m\u001b[32m243\u001b[39m     (\u001b[43mdaily_receivals\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdate_arrival\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m<\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m),\n\u001b[32m    244\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mnet_weight\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    245\u001b[39m ].sum()\n\u001b[32m    247\u001b[39m feats[\u001b[33m\"\u001b[39m\u001b[33mcum_weight\u001b[39m\u001b[33m\"\u001b[39m] = cum_weight\n\u001b[32m    248\u001b[39m train_rows.append(feats)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/pandas/core/ops/common.py:76\u001b[39m, in \u001b[36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     72\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[32m     74\u001b[39m other = item_from_zerodim(other)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/pandas/core/arraylike.py:52\u001b[39m, in \u001b[36mOpsMixin.__le__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m__le__\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__le__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mle\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/pandas/core/series.py:6130\u001b[39m, in \u001b[36mSeries._cmp_method\u001b[39m\u001b[34m(self, other, op)\u001b[39m\n\u001b[32m   6127\u001b[39m lvalues = \u001b[38;5;28mself\u001b[39m._values\n\u001b[32m   6128\u001b[39m rvalues = extract_array(other, extract_numpy=\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m6130\u001b[39m res_values = \u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6132\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._construct_result(res_values, name=res_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/pandas/core/ops/array_ops.py:344\u001b[39m, in \u001b[36mcomparison_op\u001b[39m\u001b[34m(left, right, op)\u001b[39m\n\u001b[32m    341\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m lvalues.dtype == \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m344\u001b[39m     res_values = \u001b[43mcomp_method_OBJECT_ARRAY\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    347\u001b[39m     res_values = _na_arithmetic_op(lvalues, rvalues, op, is_cmp=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/pandas/core/ops/array_ops.py:129\u001b[39m, in \u001b[36mcomp_method_OBJECT_ARRAY\u001b[39m\u001b[34m(op, x, y)\u001b[39m\n\u001b[32m    127\u001b[39m     result = libops.vec_compare(x.ravel(), y.ravel(), op)\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m     result = \u001b[43mlibops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscalar_compare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result.reshape(x.shape)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # == Prepare and build features and training set ==\n",
    "    receivals, purchase_orders, daily_receivals, qty_2025_rm_id, scheduled_rm_ids, delays, delay_stats, active_rm_ids = prepareData()\n",
    "    df_train = buildTrainSet(receivals, daily_receivals, purchase_orders, delays, scheduled_rm_ids, qty_2025_rm_id, \"trainingSet.csv\")\n",
    "    #df_train = pd.read_csv(\"trainingSet.csv\")\n",
    "\n",
    "    # == Train global LGBM ==\n",
    "    model_dir = \"lgbm_global_optuna.txt\"\n",
    "    model = train_global_model_lgbm_optuna(df_train, model_dir=model_dir)\n",
    "    booster = model.booster_\n",
    "\n",
    "    # == Forecast for 2025 ==\n",
    "    prediction_path = \"lgbm_global.csv\"\n",
    "    \n",
    "    forecast2025(booster, FORECAST_START, FORECAST_END, scheduled_rm_ids, \n",
    "                                 daily_receivals, purchase_orders, delays, qty_2025_rm_id, receivals, \n",
    "                                 pred_path=prediction_path)\n",
    "    \n",
    "    # == Create submission == \n",
    "    createSubmission(prediction_path, \"data/prediction_mapping.csv\", \"submission2.csv\")\n",
    "    return\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Jupyter)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
